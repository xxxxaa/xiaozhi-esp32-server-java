// éŸ³é¢‘å¤„ç†æœåŠ¡ - Vue3 TypeScriptç‰ˆæœ¬

import { log } from './websocket'

// =============================
// ç±»å‹å®šä¹‰
// =============================

interface OpusDecoderModule {
  _opus_decoder_get_size: (channels: number) => number
  _opus_decoder_init: (decoder: number, sampleRate: number, channels: number) => number
  _opus_decode: (
    decoder: number,
    data: number,
    len: number,
    pcm: number,
    frameSize: number,
    decodeFec: number
  ) => number
  _malloc: (size: number) => number
  _free: (ptr: number) => void
  HEAPU8: Uint8Array
  HEAP16: Int16Array
}

interface OpusDecoder {
  channels: number
  rate: number
  frameSize: number
  module: OpusDecoderModule
  decoderPtr: number | null
  init: () => boolean
  decode: (opusData: Uint8Array) => Int16Array
  destroy: () => void
}

interface AudioConfig {
  sampleRate: number
  channels: number
  frameSize: number
}

interface StreamingContext {
  queue: number[]
  playing: boolean
  endOfStream: boolean
  source: AudioBufferSourceNode | null
  totalSamples: number
  lastPlayTime: number
  analyser: AnalyserNode | null
  decodeOpusFrames: (opusFrames: Uint8Array[]) => Promise<void>
  startPlaying: () => void
}

declare global {
  interface Window {
    Module?: any
    ModuleInstance?: OpusDecoderModule
    audioContext?: AudioContext
    streamingContext?: StreamingContext
    enableAudio?: () => Promise<boolean>
  }
}

// =============================
// é…ç½®
// =============================

const defaultConfig: AudioConfig = {
  sampleRate: 16000,
  channels: 1,
  frameSize: 960 // 60ms @ 16kHz
}

// =============================
// çŠ¶æ€å˜é‡
// =============================

let audioContext: AudioContext | null = null
let opusDecoder: OpusDecoder | null = null
let audioBufferQueue: Uint8Array[] = []
let isAudioBuffering = false
let isAudioPlaying = false
let streamingContext: StreamingContext | null = null
let audioContextResumePromise: Promise<AudioContext> | null = null

// =============================
// éŸ³é¢‘ä¸Šä¸‹æ–‡åˆå§‹åŒ–
// =============================

async function initAudioContext(): Promise<AudioContext | null> {
  if (audioContext) {
    if (audioContext.state === 'suspended' && !audioContextResumePromise) {
      audioContextResumePromise = new Promise((resolve) => {
        log('éŸ³é¢‘ä¸Šä¸‹æ–‡å·²æš‚åœã€‚éœ€è¦ç”¨æˆ·äº¤äº’æ‰èƒ½æ¢å¤ã€‚', 'warning')

        const resumeAudioContext = async () => {
          try {
            if (audioContext) {
              await audioContext.resume()
              log('éŸ³é¢‘ä¸Šä¸‹æ–‡å·²é€šè¿‡ç”¨æˆ·äº¤äº’æ¢å¤', 'success')
              resolve(audioContext)

              ;['click', 'touchstart', 'keydown'].forEach(event => {
                document.removeEventListener(event, resumeAudioContext)
              })
              audioContextResumePromise = null
            }
          } catch (err) {
            log('æ¢å¤éŸ³é¢‘ä¸Šä¸‹æ–‡å¤±è´¥: ' + err, 'error')
          }
        }

        ;['click', 'touchstart', 'keydown'].forEach(event => {
          document.addEventListener(event, resumeAudioContext, { once: false })
        })
      })

      return audioContextResumePromise
    }
    return audioContext
  }

  try {
    const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext
    audioContext = new AudioContextClass({
      sampleRate: defaultConfig.sampleRate,
      latencyHint: 'interactive'
    })

    if (audioContext.state === 'suspended') {
      log('æ–°åˆ›å»ºçš„éŸ³é¢‘ä¸Šä¸‹æ–‡å¤„äºæš‚åœçŠ¶æ€ã€‚éœ€è¦ç”¨æˆ·äº¤äº’æ‰èƒ½å¯åŠ¨ã€‚', 'warning')

      audioContextResumePromise = new Promise((resolve) => {
        const resumeAudioContext = async () => {
          try {
            if (audioContext) {
              await audioContext.resume()
              log('éŸ³é¢‘ä¸Šä¸‹æ–‡å·²é€šè¿‡ç”¨æˆ·äº¤äº’å¯åŠ¨', 'success')
              resolve(audioContext)

              ;['click', 'touchstart', 'keydown'].forEach(event => {
                document.removeEventListener(event, resumeAudioContext)
              })
              audioContextResumePromise = null
            }
          } catch (err) {
            log('å¯åŠ¨éŸ³é¢‘ä¸Šä¸‹æ–‡å¤±è´¥: ' + err, 'error')
          }
        }

        ;['click', 'touchstart', 'keydown'].forEach(event => {
          document.addEventListener(event, resumeAudioContext, { once: false })
        })
      })

      return audioContextResumePromise
    }

    window.audioContext = audioContext

    return audioContext
  } catch (error) {
    log('åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡å¤±è´¥:' + error, 'error')
    return null
  }
}

// =============================
// Opus åº“åŠ è½½
// =============================

function checkOpusLoaded(): boolean {
  try {
    if (typeof window.Module === 'undefined') {
      return false
    }

    if (
      typeof window.Module.instance !== 'undefined' &&
      typeof window.Module.instance._opus_decoder_get_size === 'function'
    ) {
      window.ModuleInstance = window.Module.instance
      log('Opusåº“åŠ è½½æˆåŠŸï¼ˆä½¿ç”¨Module.instanceï¼‰', 'success')
      return true
    }

    if (typeof window.Module._opus_decoder_get_size === 'function') {
      window.ModuleInstance = window.Module
      log('Opusåº“åŠ è½½æˆåŠŸï¼ˆä½¿ç”¨å…¨å±€Moduleï¼‰', 'success')
      return true
    }

    if (
      window.ModuleInstance &&
      typeof window.ModuleInstance._opus_decoder_get_size === 'function'
    ) {
      log('Opusåº“å·²åŠ è½½ï¼ˆä½¿ç”¨ModuleInstanceï¼‰', 'success')
      return true
    }

    return false
  } catch (err) {
    log(`Opusåº“æ£€æŸ¥å¤±è´¥: ${err}`, 'error')
    return false
  }
}

export function loadOpusLibrary(): Promise<boolean> {
  return new Promise(resolve => {
    if (checkOpusLoaded()) {
      resolve(true)
      return
    }

    log('å°è¯•åŠ è½½libopus.js', 'info')

    const possiblePaths = [
      '/libopus.js',
      '/js/libopus.js',
      '/static/js/libopus.js',
      './libopus.js',
      '../js/libopus.js'
    ]

    const script = document.createElement('script')
    script.async = true

    script.onload = () => {
      log('libopus.jsè„šæœ¬åŠ è½½æˆåŠŸï¼Œç­‰å¾…åˆå§‹åŒ–', 'success')

      const maxAttempts = 100
      let attempts = 0

      const checkModule = () => {
        if (checkOpusLoaded()) {
          log('Opusåº“åˆå§‹åŒ–æˆåŠŸ', 'success')
          resolve(true)
          return
        }

        if (attempts >= maxAttempts) {
          log('Opusåº“åˆå§‹åŒ–è¶…æ—¶', 'error')
          resolve(false)
          return
        }

        attempts++
        setTimeout(checkModule, 100)
      }

      checkModule()
    }

    script.onerror = () => {
      log('libopus.jsåŠ è½½å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªè·¯å¾„', 'warning')
      tryNextPath()
    }

    let pathIndex = 0

    function tryNextPath() {
      if (pathIndex >= possiblePaths.length) {
        log('æ‰€æœ‰è·¯å¾„éƒ½å°è¯•å¤±è´¥', 'error')
        resolve(false)
        return
      }

      const path = possiblePaths[pathIndex]
      pathIndex++

      if (!path) {
        log('è·¯å¾„ä¸ºç©ºï¼ŒåŠ è½½å¤±è´¥', 'error')
        resolve(false)
        return
      }

      log(`å°è¯•ä»è·¯å¾„åŠ è½½: ${path}`, 'info')
      script.src = path
      document.head.appendChild(script)
    }

    tryNextPath()
  })
}

// =============================
// Opus è§£ç å™¨
// =============================

function createOpusDecoder(mod: OpusDecoderModule): OpusDecoder {
  try {
    const SAMPLE_RATE = 16000
    const CHANNELS = 1
    const FRAME_SIZE = 960

    const decoder: OpusDecoder = {
      channels: CHANNELS,
      rate: SAMPLE_RATE,
      frameSize: FRAME_SIZE,
      module: mod,
      decoderPtr: null,

      init: function () {
        if (this.decoderPtr) return true

        const decoderSize = mod._opus_decoder_get_size(this.channels)
        log('Opusè§£ç å™¨å¤§å°:' + decoderSize + 'å­—èŠ‚', 'debug')

        this.decoderPtr = mod._malloc(decoderSize)
        if (!this.decoderPtr) {
          throw new Error('æ— æ³•åˆ†é…è§£ç å™¨å†…å­˜')
        }

        const err = mod._opus_decoder_init(this.decoderPtr, this.rate, this.channels)

        if (err < 0) {
          this.destroy()
          throw new Error(`Opusè§£ç å™¨åˆå§‹åŒ–å¤±è´¥: ${err}`)
        }

        log('Opusè§£ç å™¨åˆå§‹åŒ–æˆåŠŸ', 'success')
        return true
      },

      decode: function (opusData: Uint8Array): Int16Array {
        if (!this.decoderPtr) {
          if (!this.init()) {
            throw new Error('è§£ç å™¨æœªåˆå§‹åŒ–ä¸”æ— æ³•åˆå§‹åŒ–')
          }
        }

        try {
          const mod = this.module

          const opusPtr = mod._malloc(opusData.length)
          mod.HEAPU8.set(opusData, opusPtr)

          const pcmPtr = mod._malloc(this.frameSize * 2)

          const decodedSamples = mod._opus_decode(
            this.decoderPtr!,
            opusPtr,
            opusData.length,
            pcmPtr,
            this.frameSize,
            0
          )

          if (decodedSamples < 0) {
            mod._free(opusPtr)
            mod._free(pcmPtr)
            throw new Error(`Opusè§£ç å¤±è´¥: ${decodedSamples}`)
          }

          const decodedData = new Int16Array(decodedSamples)
          for (let i = 0; i < decodedSamples; i++) {
            const heapValue = mod.HEAP16[(pcmPtr >> 1) + i]
            if (heapValue !== undefined) {
              decodedData[i] = heapValue
            }
          }

          mod._free(opusPtr)
          mod._free(pcmPtr)

          return decodedData
        } catch (error) {
          log('Opusè§£ç é”™è¯¯:' + error, 'error')
          return new Int16Array(0)
        }
      },

      destroy: function () {
        if (this.decoderPtr) {
          this.module._free(this.decoderPtr)
          this.decoderPtr = null
        }
      }
    }

    if (!decoder.init()) {
      throw new Error('Opusè§£ç å™¨åˆå§‹åŒ–å¤±è´¥')
    }

    opusDecoder = decoder
    return decoder
  } catch (error) {
    log('Opusè§£ç å™¨åˆå§‹åŒ–å¤±è´¥:' + error, 'error')
    opusDecoder = null
    throw error
  }
}

export async function initOpusDecoder(): Promise<OpusDecoder | null> {
  if (opusDecoder) {
    return opusDecoder
  }

  try {
    const opusLoaded = await loadOpusLibrary()
    if (!opusLoaded) {
      throw new Error('Opusåº“æœªåŠ è½½')
    }

    const mod = window.ModuleInstance
    if (!mod) {
      throw new Error('ModuleInstanceä¸å¯ç”¨')
    }

    return createOpusDecoder(mod)
  } catch (error) {
    log(`åˆå§‹åŒ–Opusè§£ç å™¨å¤±è´¥:` + error, 'error')
    throw error
  }
}

// =============================
// éŸ³é¢‘æ’­æ”¾
// =============================

function convertInt16ToFloat32(int16Data: Int16Array): number[] {
  const float32Data: number[] = []
  for (let i = 0; i < int16Data.length; i++) {
    const sample = int16Data[i]
    if (sample !== undefined) {
      float32Data.push(sample / (sample < 0 ? 0x8000 : 0x7fff))
    }
  }
  return float32Data
}

function resetAudioBuffer(): void {
  audioBufferQueue = []
  isAudioBuffering = false
  isAudioPlaying = false
}

function addAudioToBuffer(opusData: Uint8Array): boolean {
  audioBufferQueue.push(opusData)

  // å¦‚æœæ²¡æœ‰åœ¨æ’­æ”¾ï¼Œå¯åŠ¨ç¼“å†²æµç¨‹
  if (!isAudioPlaying && !isAudioBuffering) {
    startAudioBuffering()
  }
  // å¦‚æœæ­£åœ¨æ’­æ”¾ä½†å½“å‰æ²¡æœ‰æ’­æ”¾ç‰‡æ®µï¼Œä¸”æœ‰è¶³å¤Ÿæ•°æ®ï¼Œè§¦å‘è§£ç 
  else if (isAudioPlaying && streamingContext && !streamingContext.playing && audioBufferQueue.length >= 3) {
    log('ğŸ”„ æ’­æ”¾ä¸­æ”¶åˆ°æ–°æ•°æ®ï¼Œç«‹å³è§£ç ', 'debug')
    const frames = [...audioBufferQueue]
    audioBufferQueue = []
    streamingContext.decodeOpusFrames(frames)
  }

  return true
}

function startAudioBuffering(): boolean {
  if (isAudioBuffering || isAudioPlaying) return false

  isAudioBuffering = true
  log('å¼€å§‹éŸ³é¢‘ç¼“å†²...', 'info')

  initOpusDecoder().catch(error => {
    log(`é¢„åˆå§‹åŒ–Opusè§£ç å™¨å¤±è´¥: ${error}`, 'warning')
  })

  setTimeout(() => {
    if (isAudioBuffering && audioBufferQueue.length > 0) {
      log(`ç¼“å†²è¶…æ—¶ï¼Œå½“å‰ç¼“å†²åŒ…æ•°: ${audioBufferQueue.length}ï¼Œå¼€å§‹æ’­æ”¾`, 'info')
      playBufferedAudio()
    }
  }, 300)

  const bufferThreshold = 3
  const bufferCheckInterval = setInterval(() => {
    if (!isAudioBuffering) {
      clearInterval(bufferCheckInterval)
      return
    }

    if (audioBufferQueue.length >= bufferThreshold) {
      clearInterval(bufferCheckInterval)
      log(`å·²ç¼“å†² ${audioBufferQueue.length} ä¸ªéŸ³é¢‘åŒ…ï¼Œå¼€å§‹æ’­æ”¾`, 'info')
      playBufferedAudio()
    }
  }, 50)

  return true
}

async function playBufferedAudio(): Promise<boolean> {
  if (isAudioPlaying || audioBufferQueue.length === 0) return false

  isAudioPlaying = true
  isAudioBuffering = false

  try {
    if (!audioContext) {
      audioContext = await initAudioContext()
    }

    if (!audioContext || audioContext.state === 'suspended') {
      log('éŸ³é¢‘ä¸Šä¸‹æ–‡è¢«æš‚åœï¼Œç­‰å¾…ç”¨æˆ·äº¤äº’...', 'warning')
      isAudioPlaying = false
      return false
    }

    if (!opusDecoder) {
      log('åˆå§‹åŒ–Opusè§£ç å™¨...', 'info')
      try {
        opusDecoder = await initOpusDecoder()
        if (!opusDecoder) {
          throw new Error('è§£ç å™¨åˆå§‹åŒ–å¤±è´¥')
        }
        log('Opusè§£ç å™¨åˆå§‹åŒ–æˆåŠŸ', 'success')
      } catch (error) {
        log('Opusè§£ç å™¨åˆå§‹åŒ–å¤±è´¥: ' + error, 'error')
        isAudioPlaying = false
        return false
      }
    }

    if (!streamingContext) {
      streamingContext = {
        queue: [],
        playing: false,
        endOfStream: false,
        source: null,
        totalSamples: 0,
        lastPlayTime: 0,
        analyser: null,

        decodeOpusFrames: async function (opusFrames: Uint8Array[]) {
          if (!opusDecoder) {
            log('Opusè§£ç å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•è§£ç ', 'error')
            return
          }

          let decodedSamples: number[] = []
          for (const frame of opusFrames) {
            try {
              const frameData = opusDecoder.decode(frame)
              if (frameData && frameData.length > 0) {
                const floatData = convertInt16ToFloat32(frameData)
                decodedSamples.push(...floatData)
              }
            } catch (error) {
              log('Opusè§£ç å¤±è´¥: ' + error, 'error')
            }
          }

          if (decodedSamples.length > 0) {
            this.queue.push(...decodedSamples)
            this.totalSamples += decodedSamples.length

            const minSamples = defaultConfig.sampleRate * 0.1
            if (!this.playing && this.queue.length >= minSamples) {
              this.startPlaying()
            }
          } else {
            log('æ²¡æœ‰æˆåŠŸè§£ç çš„æ ·æœ¬', 'warning')
          }
        },

        startPlaying: function () {
          if (this.playing || this.queue.length === 0 || !audioContext) return

          if (audioContext.state === 'suspended') {
            log('éŸ³é¢‘ä¸Šä¸‹æ–‡ä»å¤„äºæš‚åœçŠ¶æ€ï¼Œæ— æ³•æ’­æ”¾', 'warning')
            return
          }

          this.playing = true

          const minPlaySamples = Math.min(this.queue.length, defaultConfig.sampleRate)
          const currentSamples = this.queue.splice(0, minPlaySamples)
          const audioBuffer = audioContext.createBuffer(
            defaultConfig.channels,
            currentSamples.length,
            defaultConfig.sampleRate
          )

          const channelData = audioBuffer.getChannelData(0)
          for (let i = 0; i < currentSamples.length; i++) {
            const sample = currentSamples[i]
            if (sample !== undefined) {
              channelData[i] = sample
            }
          }

          this.source = audioContext.createBufferSource()
          this.source.buffer = audioBuffer

          const gainNode = audioContext.createGain()

          const fadeDuration = 0.02
          gainNode.gain.setValueAtTime(0, audioContext.currentTime)
          gainNode.gain.linearRampToValueAtTime(1, audioContext.currentTime + fadeDuration)

          const duration = audioBuffer.duration
          if (duration > fadeDuration * 2) {
            gainNode.gain.setValueAtTime(1, audioContext.currentTime + duration - fadeDuration)
            gainNode.gain.linearRampToValueAtTime(0, audioContext.currentTime + duration)
          }

          const analyserNode = audioContext.createAnalyser()
          analyserNode.fftSize = 256
          analyserNode.smoothingTimeConstant = 0.8

          this.source.connect(analyserNode)
          analyserNode.connect(gainNode)
          gainNode.connect(audioContext.destination)

          this.analyser = analyserNode

          this.lastPlayTime = audioContext.currentTime

          log(
            `å¼€å§‹æ’­æ”¾ ${currentSamples.length} ä¸ªæ ·æœ¬ï¼Œçº¦ ${(currentSamples.length / defaultConfig.sampleRate).toFixed(2)} ç§’`,
            'debug'
          )

          this.source.onended = () => {
            this.source = null
            this.analyser = null
            this.playing = false

            // ç»§ç»­æ’­æ”¾é˜Ÿåˆ—ä¸­çš„æ•°æ®
            if (this.queue.length > 0) {
              setTimeout(() => this.startPlaying(), 10)
            }
            // æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„ç¼“å†²æ•°æ®
            else if (audioBufferQueue.length > 0) {
              const frames = [...audioBufferQueue]
              audioBufferQueue = []
              this.decodeOpusFrames(frames)
            }
            // æµå·²æ˜ç¡®ç»“æŸ
            else if (this.endOfStream) {
              log('ğŸ éŸ³é¢‘æ’­æ”¾å®Œæˆï¼ˆæµç»“æŸï¼‰', 'info')
              isAudioPlaying = false
              streamingContext = null
              window.streamingContext = undefined
            }
            // ç­‰å¾…æ›´å¤šæ•°æ®ï¼ˆä¸è®¾ç½®è¶…æ—¶ï¼ŒæŒç»­ç­‰å¾…ï¼‰
            else {
              log('â³ ç­‰å¾…æ›´å¤šéŸ³é¢‘æ•°æ®...', 'debug')
              // ä¸åšä»»ä½•å¤„ç†ï¼Œä¿æŒ isAudioPlaying = true
              // å½“æ–°æ•°æ®åˆ°è¾¾æ—¶ï¼Œä¼šé€šè¿‡ addAudioToBuffer è§¦å‘ç»§ç»­æ’­æ”¾
            }
          }

          this.source.start()
        }
      }

      window.streamingContext = streamingContext
    }

    const frames = [...audioBufferQueue]
    audioBufferQueue = []

    await streamingContext.decodeOpusFrames(frames)
    return true
  } catch (error) {
    log(`æ’­æ”¾å·²ç¼“å†²çš„éŸ³é¢‘å‡ºé”™:` + error, 'error')
    isAudioPlaying = false
    streamingContext = null
    window.streamingContext = undefined

    return false
  }
}

export function stopAudioPlayback(): boolean {
  try {
    isAudioPlaying = false
    isAudioBuffering = false

    if (streamingContext && streamingContext.source) {
      try {
        streamingContext.source.stop()
        streamingContext.source = null
        streamingContext.analyser = null
      } catch (e) {
        // å¿½ç•¥å·²åœæ­¢çš„éŸ³é¢‘æºé”™è¯¯
      }
    }

    audioBufferQueue = []
    streamingContext = null

    window.streamingContext = undefined

    if (window.dispatchEvent) {
      window.dispatchEvent(new CustomEvent('audio-playback-stopped'))
    }

    log('éŸ³é¢‘æ’­æ”¾å·²åœæ­¢', 'info')
    return true
  } catch (error) {
    log(`åœæ­¢éŸ³é¢‘æ’­æ”¾å¤±è´¥:` + error, 'error')
    return false
  }
}

// =============================
// å¯¼å‡ºå‡½æ•°
// =============================

export async function initAudio(): Promise<boolean> {
  try {
    const context = await initAudioContext()

    window.enableAudio = async function () {
      try {
        if (audioContext && audioContext.state === 'suspended') {
          await audioContext.resume()
          log('éŸ³é¢‘ä¸Šä¸‹æ–‡å·²æ¢å¤', 'success')
        }

        let opusLoaded = false
        for (let i = 0; i < 3; i++) {
          try {
            opusLoaded = await loadOpusLibrary()
            if (opusLoaded) {
              log(`Opusåº“åŠ è½½æˆåŠŸ (å°è¯• ${i + 1}/3)`, 'success')
              break
            }
          } catch (err) {
            log(`å°è¯• ${i + 1}/3 åŠ è½½libopus.jså¤±è´¥ï¼Œå°†é‡è¯•`, 'warning')
          }
        }

        if (!opusLoaded) {
          log('æ‰€æœ‰Opusåº“åŠ è½½å°è¯•å‡å¤±è´¥ï¼ŒéŸ³é¢‘æ’­æ”¾åŠŸèƒ½å°†ä¸å¯ç”¨', 'error')
          return false
        }

        try {
          await initOpusDecoder()
          log('Opusè§£ç å™¨åˆå§‹åŒ–æˆåŠŸ', 'success')
          return true
        } catch (err) {
          log(`Opusè§£ç å™¨åˆå§‹åŒ–å¤±è´¥: ${err}ï¼ŒéŸ³é¢‘æ’­æ”¾åŠŸèƒ½å°†ä¸å¯ç”¨`, 'error')
          return false
        }
      } catch (error) {
        log('å¯ç”¨éŸ³é¢‘å¤±è´¥:' + error, 'error')
        return false
      }
    }

    await loadOpusLibrary()

    log('éŸ³é¢‘ç³»ç»Ÿå·²åˆå§‹åŒ–ã€‚è¯·é€šè¿‡ç”¨æˆ·äº¤äº’å¯ç”¨éŸ³é¢‘åŠŸèƒ½ã€‚', 'info')

    return true
  } catch (error) {
    log('åˆå§‹åŒ–éŸ³é¢‘å¤±è´¥:' + error, 'error')
    return false
  }
}

export async function handleBinaryAudioMessage(data: ArrayBuffer): Promise<boolean> {
  try {
    log(`æ”¶åˆ°ArrayBufferéŸ³é¢‘æ•°æ®ï¼Œå¤§å°: ${data.byteLength}å­—èŠ‚`, 'debug')

    const opusData = new Uint8Array(data)

    if (opusData.length > 0) {
      addAudioToBuffer(opusData)

      if (window.dispatchEvent) {
        window.dispatchEvent(
          new CustomEvent('audio-data-received', {
            detail: { dataLength: opusData.length }
          })
        )
      }

      return true
    } else {
      log('æ”¶åˆ°ç©ºéŸ³é¢‘æ•°æ®å¸§ï¼Œå¯èƒ½æ˜¯ç»“æŸæ ‡å¿—', 'warning')

      if (audioBufferQueue.length > 0 && !isAudioPlaying) {
        playBufferedAudio()
      }

      if (isAudioPlaying && streamingContext) {
        streamingContext.endOfStream = true
      }

      if (window.dispatchEvent) {
        window.dispatchEvent(new CustomEvent('audio-playback-ended'))
      }

      return true
    }
  } catch (error) {
    log('å¤„ç†äºŒè¿›åˆ¶æ¶ˆæ¯å‡ºé”™:' + error, 'error')
    return false
  }
}

export function cleanupAudio(): boolean {
  try {
    stopAudioPlayback()

    if (opusDecoder && opusDecoder.destroy) {
      opusDecoder.destroy()
      opusDecoder = null
    }

    if (audioContext && audioContext.state !== 'closed') {
      audioContext.close()
      audioContext = null
    }

    resetAudioBuffer()

    log('éŸ³é¢‘èµ„æºå·²æ¸…ç†', 'info')
    return true
  } catch (error) {
    log('æ¸…ç†éŸ³é¢‘èµ„æºå¤±è´¥:' + error, 'error')
    return false
  }
}

export function getAudioState() {
  return {
    isAudioBuffering,
    isAudioPlaying,
    audioBufferQueue,
    analyser: streamingContext && streamingContext.analyser
  }
}

